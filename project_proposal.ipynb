{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b70928a-7178-4285-899d-3c46c32e63fa",
   "metadata": {},
   "source": [
    "# Spectral Sounds: Unveiling Music Genre Classification through Audio Spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60089440-9db3-41c9-a1e6-48aa94f61532",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "With the dominance of digital music streaming, music genre classification is an increasingly important way to develop algorithms for suggesting new songs to users. Without a way to analyze the abstract aspects of each song such as mood and tone, these algorithms must be able to make accurate predictions based only on the quantitative characteristics of the audio itself.\n",
    "\n",
    "Hence, we aim to answer the following research question: **Can we predict the genre of a song based on its audio spectrograph information?**\n",
    "In particular, we will focus on the **classical, jazz, pop, and rock music** genres\n",
    "\n",
    "### Dataset\n",
    "\n",
    "We will be using the Music Genre Classification dataset by Andrada on [Kaggle](https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification). It includes observations for 1000 30-second audio snippets, each consisting of 60 variables describing its audio spectrogram. Each observation is also labeled with the genre of music that is it part of, along with a `.wav` musical recording. \n",
    "\n",
    "A spectrogram is a visual way of representing the intensity of a signal over time at various frequencies present in a particular waveform. The quantitative audio features are extracted from recordings through the python library `librosa`, and it describes the average and variance of different aspects of the audio spectrogram. Some examples includes the range of frequencies, the distribution of musical pitch, tempo, and audio loudness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197fbfda-03a4-477f-bbcd-6fa79a7ce922",
   "metadata": {},
   "source": [
    "## Preliminary Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd3e2b7-426d-45bc-b0e6-c369b22d0d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://raw.githubusercontent.com/arthu-rguo/dsci-100-proj/master/features_30_sec.csv\n",
    "\n",
    "start doing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aca2ae-cc1f-4297-8c21-7b5d522aab5e",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "The data analysis process for the project on song genre classification based on audio features involves several steps. These include data preprocessing, feature extraction, data exploration, data splitting, model training using KNN algorithm, model evaluation, model optimization, interpreting the results, and reporting the findings. By following this process, you can extract relevant features from the audio data, train a KNN model, evaluate its performance, and gain insights into the relationships between audio features and genre classification. The analysis results can be summarized and communicated effectively to provide valuable conclusions and recommendations.\n",
    "\n",
    "A few potentially useful predictor variables are as follows:\n",
    "\n",
    "1. **Chroma feature:** It measures the distribution of musical pitch, and can capture the tonal content and can be helpful in distinguishing different genres that have distinct harmonic patterns.\n",
    "\n",
    "2. **RMS (Root Mean Square) values:** Measures the perceived loudness of the signal. It can be useful in differentiating genres with varying loudness characteristics.\n",
    "\n",
    "3. **Spectral centroid:** Measures the average frequency of the signal. It can aid in identifying genres that tend to have specific frequency characteristics.\n",
    "\n",
    "4. **Spectral bandwidth:** Measures the average spread of frequencies of the signal. It can help differentiate genres with varying spectral width or frequency spread.\n",
    "\n",
    "5. **Zero crossing rate:** It provides information about the signal's fluctuations and can be useful in distinguishing genres with different levels of rhythmic complexity or smoothness.\n",
    "\n",
    "We also intend to perform iterative predictor variable selection, similar to the technique demonstrated in the textbook.\n",
    "\n",
    "### Visualization\n",
    "**Bar chart:** Display the distribution of song genres using bars to represent each genre's frequency.\n",
    "**Scatter plot:** Plot the audio features of songs as data points on a graph to identify clusters or patterns.\n",
    "**Line graph:** Track the variation of specific audio features across genres or time periods using lines.\n",
    "**Box plot:** Illustrate the distribution of audio features within genres using boxes and whiskers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fc5134-18d7-407b-ba1c-24756178df2e",
   "metadata": {},
   "source": [
    "## Expected Outcomes and Significance\n",
    "\n",
    "### Expected Findings\n",
    "Different genres of music often use different instruments that have different tones, timbre, and pitches. They also have different tempos, harmonies and general qualities that differentiate them from one another to a human ear. Perhaps these differences can be isolated and processed in such a way that a machine can also reliably classify genres based on its spectrograph information. The project anticipates identifying informative and discriminative features that strongly influence genre classification. It also aims to reveal genre-specific patterns within the audio features, enabling a deeper understanding of the distinguishing characteristics of different music genres. Additionally, the project expects to compare the performance of different classification algorithms, evaluate feature importance, assess model generalization, uncover genre relationships, and explore potential applications in music-related domains. Overall, the project aims to provide valuable insights and advancements in genre classification based on audio features.\n",
    "\n",
    "### Potential Impacts\n",
    "Overall, the findings from the data science project can have practical implications in various domains, including music recommendation, streaming platforms, marketing strategies, music analysis, and interactive applications. They can contribute to improving user experiences, enhancing music discovery, and enabling better insights and decision-making within the music industry and related fields.\n",
    "\n",
    "### Future Questions\n",
    "Which combination of audio features yields the best genre classification accuracy?\n",
    "How does the performance of KNN classification compare to other algorithms for genre classification?\n",
    "How can genre classification models handle songs that contain elements of multiple genres or blur genre boundaries?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
